import numpy as np
import re, struct, collections

#https://github.com/easy-electrophysiology/load-heka-python/blob/main/load_heka_python/trees/SharedTrees.py#L118


class Struct(object):
    """High-level wrapper around struct.Struct that makes it a bit easier to
    unpack large, nested structures.

    * Unpacks to dictionary allowing fields to be retrieved by name
    * Optionally massages field data on read
    * Handles arrays and nested structures

    *fields* must be a list of tuples like (name, format) or (name, format, function)
    where *format* must be a simple struct format string like 'i', 'd',
    '32s', or '4d'; or another Struct instance.

    *function* may be either a function that filters the data for that field
    or None to exclude the field altogether.

    If *size* is given, then an exception will be raised if the final struct size
    does not match the given size.

    Example::

        class MyStruct(Struct):
            field_info = [
                ('char_field', 'c'),                # single char
                ('char_array', '8c'),               # list of 8 chars
                ('str_field',  '8s', cstr),         # C string of len 8
                ('sub_struct', MyOtherStruct),      # dict generated by s2.unpack
                ('filler', '32s', None),            # ignored field
            ]
            size_check = 300

        fh = open(fname, 'rb')
        data = MyStruct(fh)

    """
    field_info = None
    size_check = None
    _fields_parsed = None



    def __init__(self, data, endian='<'):
        """Read the structure from *data* and return an ordered dictionary of
        fields.

        *data* may be a string or file.
        *endian* may be '<' or '>'
        """
        field_info = self._field_info()
        if not isinstance(data, (str, bytes)):
            data = data.read(self._le_struct.size)
        if endian == '<':
            items = self._le_struct.unpack(data)
        elif endian == '>':
            items = self._be_struct.unpack(data)
        else:
            raise ValueError('Invalid endian: %s' % endian)

        fields = collections.OrderedDict()

        i = 0
        for name, fmt, func in field_info:
            # pull item(s) out of the list based on format string
            if len(fmt) == 1 or fmt[-1] == 's':
                item = items[i]
                i += 1
            else:
                n = int(fmt[:-1])
                item = items[i:i+n]
                i += n

            # try unpacking sub-structure
            if isinstance(func, tuple):
                substr, func = func
                item = substr(item, endian)

            # None here means the field should be omitted
            if func is None:
                continue
            # handle custom massaging function
            if func is not True:
                item = func(item)
            fields[name] = item

            setattr(self, name, item)

        self.fields = fields

    @classmethod
    def _field_info(cls):
        if cls._fields_parsed is not None:
            return cls._fields_parsed

        fmt = ''
        fields = []
        for items in cls.field_info:
            if len(items) == 3:
                name, ifmt, func = items
            else:
                name, ifmt = items
                func = True

            if isinstance(ifmt, type) and issubclass(ifmt, Struct):
                func = (ifmt, func) # instructs to unpack with sub-struct before calling function
                ifmt = '%ds' % ifmt.size()
            elif len(ifmt) > 1 and re.match(r'\d*[xcbB?hHiIlLqQfdspP]', ifmt) is None:
                raise TypeError('Unsupported format string "%s"' % ifmt)

            fields.append((name, ifmt, func))
            fmt += ifmt
        cls._le_struct = struct.Struct('<' + fmt)
        cls._be_struct = struct.Struct('>' + fmt)
        cls._fields_parsed = fields
        print(cls._le_struct.size, cls.size_check)
        if cls.size_check is not None:
            assert cls._le_struct.size == cls.size_check
        return fields

    @classmethod
    def size(cls):
        cls._field_info()
        return cls._le_struct.size

    @classmethod
    def array(cls, x):
        """Return a new StructArray class of length *x* and using this struct
        as the array item type.
        """
        return type(cls.__name__+'[%d]'%x, (StructArray,),
                    {'item_struct': cls, 'array_size': x})

    def __repr__(self, indent=0):
        indent_str = '    '*indent
        r = indent_str + '%s(\n'%self.__class__.__name__
        if not hasattr(self, 'fields'):
            r = r[:-1] + '<initializing>)'
            return r
        for k,v in self.fields.items():
            if isinstance(v, Struct):
                r += indent_str + '    %s = %s\n' % (k, v.__repr__(indent=indent+1).lstrip())
            else:
                r += indent_str + '    %s = %r\n' % (k, v)
        r += indent_str + ')'
        return r

    def get_fields(self):
        """Recursively convert struct fields+values to nested dictionaries.
        """
        fields = self.fields.copy()
        for k,v in fields.items():
            if isinstance(v, StructArray):
                fields[k] = [x.get_fields() for x in v.array]
            elif isinstance(v, Struct):
                fields[k] = v.get_fields()
        return fields

class StructArray(Struct):
    item_struct = None
    array_size = None

    def __init__(self, data, endian='<'):
        if not isinstance(data, (str, bytes)):
            data = data.read(self.size())
        items = []
        isize = self.item_struct.size()
        for i in range(self.array_size):
            d = data[:isize]
            data = data[isize:]
            items.append(self.item_struct(d, endian))
        self.array = items

    def __getitem__(self, i):
        return self.array[i]

    @classmethod
    def size(self):
        return self.item_struct.size() * self.array_size

    def __repr__(self, indent=0):
        r = '    '*indent + '%s(\n' % self.__class__.__name__
        for item in self.array:
            r += item.__repr__(indent=indent+1) + ',\n'
        r += '    '*indent + ')'
        return r
    
class TreeNode(Struct):
    """Struct that also represents a node in a Pulse file tree.
    """
    def __init__(self, fh, pul, level=0):

        self.level = level
        self.children = []
        endian = pul.endian

        # The record structure in the file may differ from our expected structure
        # due to version differences, so we read the required number of bytes, and
        # then pad or truncate before unpacking the record. This will probably
        # result in corrupt data in some situations..
        realsize = pul.level_sizes[level]
        structsize = self.size()
        data = fh.read(realsize)
        diff = structsize - realsize
        if diff > 0:
            data = data + b'\0'*diff
        else:
            data = data[:structsize]

        # initialize struct data
        Struct.__init__(self, data, endian)

        # Next read the number of children
        nchild = struct.unpack(endian + 'i', fh.read(4))[0]
        level += 1
        if level >= len(pul.rectypes):
            return
        child_rectype = pul.rectypes[level]
        for i in range(nchild):
            self.children.append(child_rectype(fh, pul, level))


    def __getitem__(self, i):
        return self.children[i]

    def __len__(self):
        return len(self.children)

    def __iter__(self):
        return self.children.__iter__()

    def __repr__(self, indent=0):
        # Return a string describing this structure
        ind = '    '*indent
        srep = Struct.__repr__(self, indent)[:-1]  # exclude final parenthese
        srep += ind + '    children = %d,\n' % len(self)
        #srep += ind + 'children = [\n'
        #for ch in self:
            #srep += ch.__repr__(indent=indent+1) + ',\n'
        srep += ind + ')'
        return srep



def cstr(byt):
    """Convert C string bytes to python string.
    """
    try:
        ind = byt.index(b'\0')
    except ValueError:
        return byt
    return byt[:ind].decode('utf-8', errors='ignore')


class GroupRecord(TreeNode):
    field_info = [

        ('Mark', 'i'),
        ('Label', '32s', cstr),
        ('Text', '80s', cstr),
        ('ExperimentNumber', 'i'),
        ('GroupCount', 'i'),
        ('CRC', 'i'),
    ]
    size_check = 128

class SeriesRecord(TreeNode):
    field_info = [
            ("Mark", "i"),  # (* INT32 *)
            ("Label", "32s", cstr),  # (* String32Type *)
            ("Comment", "80s", cstr),  # (* String80Type *)
            ("SeriesCount", "i"),  # (* INT32 *)
            ("NumberSweeps", "i"),  # (* INT32 *)
            ("AmplStateOffset", "i"),  # (* INT32 *)
            ("AmplStateSeries", "i"),  # (* INT32 *)
            ("SeMethodTag", "i"),  # (* INT32 *)
            ("SeTime", "d"),  # * LONGREAL *)
            ("SePageWidth", "d"),  # * LONGREAL *)
            ("SeSwUserParamDescr", "160s"),# UserParamDescrType(4)),  # (* ARRAY[0..3] OF UserParamDescrType = 4*40 *)
            ("SeMethodName", "32s", cstr),  # (* String32Type *)
            ("SeSeUserParams1", "4d"),  # (* ARRAY[0..3] OF LONGREAL *)
            ("SeLockInParams", "96s"),#. LockInParams_v9()),  # (* SeLockInSize = 96, see "Pulsed.de" *)
            ("SeAmplifierState", "400s"),#, AmplifierState_v9()),  # (* AmplifierStateSize = 400 *)
            ("SeUsername", "80s", cstr),  # (* String80Type *)
            ("SeSeUserParamDescr1", "160s"), #UserParamDescrType(4)),  # (* ARRAY[0..3] OF UserParamDescrType = 4*40 *)
            ("SeFiller1", "i"),  # (* INT32 *)
            ("SeCRC", "I"),  # (* CARD32 *)
            ("SeSeUserParams2", "4d"),  # (* ARRAY[0..3] OF LONGREAL *)
            ("SeSeUserParamDescr2", "160s"), #UserParamDescrType(4)),  # (* ARRAY[0..3] OF UserParamDescrType = 4*40 *)
            ("SeScanParams", "96s", cstr),  # (* ScanParamsSize = 96 *)
        ]
    size_check = 1408

class SweepRecord(TreeNode):
    field_info = [
        ('Mark', 'i'),
        ('Label', '32s', cstr),
        ('AuxDataFileOffset', 'i'),
        ('StimCount', 'i'),
        ('SweepCount', 'i'),
        ('Time', 'd'),
        ('Timer', 'd'),
        ('SwUserParams', '4d'),
        ('Temperature', 'd'),
        ('OldIntSol', 'i'),
        ('OldExtSol', 'i'),
        ('DigitalIn', 'h'),
        ('SweepKind', 'h'),
        ('Filler1', 'i', None),
        ('Markers', '4d'),
        ('Filler2', 'i', None),
        ('CRC', 'i'),
    ]
    size_check = 160

class TraceRecord(TreeNode):
   field_info = [ 
            ("Mark", "i"),  # (* INT32 *)
            ("Label", "32s", cstr),  # (* String32Type *)
            ("TraceCount", "i"),  # (* INT32 *)
            ("Data", "i"),  # (* INT32 *)
            ("DataPoints", "i"),  # (* INT32 *)
            ("InternalSolution", "i"),  # (* INT32 *)
            ("AverageCount", "i"),  # (* INT32 *)
            ("LeakCount", "i"),  # (* INT32 *)
            ("LeakTraces", "i"),  # (* INT32 *)
            ("DataKind", "h"), #get_data_kind),  # (* SET16 *)
            ("Filler1", "h"),
            ("RecordingMode", "b"), #get_recording_mode),  # (* BYTE *)
            ("AmplIndex", "c"),  # (* CHAR *)
            ("DataFormat", "b"),  # (* BYTE *)
            ("DataAbscissa", "b"),  # (* BYTE *)
            ("DataScaler", "d"),  # (* LONGREAL *)
            ("TimeOffset", "d"),  # (* LONGREAL *)
            ("ZeroData", "d"),  # (* LONGREAL *)
            ("YUnit", "8s", cstr),  # (* String8Type *)
            ("XInterval", "d"),  # (* LONGREAL *)
            ("XStart", "d"),  # (* LONGREAL *)
            ("XUnit", "8s", cstr),  # (* String8Type *)
            ("YRange", "d"),  # (* LONGREAL *)
            ("YOffset", "d"),  # (* LONGREAL *)
            ("Bandwidth", "d"),  # (* LONGREAL *)
            ("PipetteResistance", "d"),  # (* LONGREAL *)
            ("CellPotential", "d"),  # (* LONGREAL *)
            ("SealResistance", "d"),  # (* LONGREAL *)
            ("CSlow", "d"),  # (* LONGREAL *)
            ("GSeries", "d"),  # (* LONGREAL *)
            ("RsValue", "d"),  # (* LONGREAL *)
            ("GLeak", "d"),  # (* LONGREAL *)
            ("MConductance", "d"),  # (* LONGREAL *)
            ("LinkDAChannel", "i"),  # (* INT32 *)
            ("ValidYrange", "?"),  # (* BOOLEAN *)
            ("AdcMode", "b"),  # (* CHAR *)        # "c" is not read properly
            ("AdcChannel", "h"),  # (* INT16 *)
            ("Ymin", "d"),  # (* LONGREAL *)
            ("Ymax", "d"),  # (* LONGREAL *)
            ("SourceChannel", "i"),  # (* INT32 *)
            ("ExternalSolution", "i"),  # (* INT32 *)
            ("CM", "d"),  # (* LONGREAL *)
            ("GM", "d"),  # (* LONGREAL *)
            ("Phase", "d"),  # (* LONGREAL *)
            ("DataCRC", "I"),  # (* CARD32 *)
            ("CRC", "I"),  # (* CARD32 *)
            ("GS", "d"),  # (* LONGREAL *)
            ("SelfChannel", "i"),  # (* INT32 *)
            # Sigtool added the below 15.08.2012
            ("InterleaveSize", "i"),  # (* INT32 *)
            ("InterleaveSkip", "i"),  # (* INT32 *)
            ("ImageIndex", "i"),  # (* INT32 *)
            ("TrMarkers", "10d"),  # (* ARRAY[0..9] OF LONGREAL *)
            ("SECM_X", "d"),  # (* LONGREAL *)
            ("SECM_Y", "d"),  # (* LONGREAL *)
            ("SECM_Z", "d"),  # (* LONGREAL *)
        ]
   size_check = 408


class Pulsed(TreeNode):
    field_info = [
        ('Version', 'i'), # (* INT32 *)
        ('Mark', 'i'), # (* INT32 *)
        ('VersionName', '32s', cstr), # (* String32Type *)
        ('AuxFileName', '80s', cstr),  # (* String80Type *)
        ('RootText', '400s', cstr), # (* String400Type *)
        ('StartTime', 'd'), # (* LONGREAL *)
        ('MaxSamples', 'i'), # (* INT32 *)
        ('CRC', 'i'), # (* CARD32 *)
        ('Features', 'h'), # (* SET16 *)
        ('Filler1', 'h', None), # (* SET16 *)
        ('Filler2', 'i', None), # (* INT32 *)
    ]
    size_check = 544

    rectypes = [
        None,
        GroupRecord,
        SeriesRecord,
        SweepRecord,
        TraceRecord
    ]

    def __init__(self, file_name, offset=0, size=None):
        fh = open(file_name, 'rb')
        fh.seek(offset)

        # read .pul header
        magic = fh.read(4)
        if magic == b'eerT':
            self.endian = '<'
        elif magic == b'Tree':
            self.endian = '>'
        else:
            raise RuntimeError('Bad file magic: %s' % magic)

        levels = struct.unpack(self.endian + 'i', fh.read(4))[0]
        # read size of each level (one int per level)
        self.level_sizes = []
        for i in range(levels):
            size = struct.unpack(self.endian + 'i', fh.read(4))[0]
            self.level_sizes.append(size)

        TreeNode.__init__(self, fh, self)

class StimulationPGF(TreeNode): # first node from root
    field_info = [
        ('Mark', 'i'),
        ('EntryName', '32s',cstr),
        ('FileName', '32s', cstr),
        ('AnalName', '32s',cstr),
        ('DataStartSegment', 'i'),
        ('DataStartTime', 'd'),
        ('SampleInterval', 'd'),
        ('SweepInterval', 'd'),
        ('LeakDelay', 'd'),
        ('FilterFactor', 'd'),
        ('NumberSweeps', 'i'),
        ('NumberLeaks', 'i'),
        ('NumberAverages', 'i'),
        ('ActualAdcChannels', 'i'),
        ('ActualDacChannels', 'i'),
        ('ExtTriggers', 'c'),
        ('NoStartWait', '?'),
        ('UseScanRate', '?'),
        ('NoContAq', '?'),
        ('HasLockIn', '?'),
        ('OldStartMacKind', 'c'),
        ('OldEndMacKind', '?'),
        ('AutoRange', 'c'),
        ('BreakNext', '?'),
        ('IsExpanded', '?'),
        ('LeakCompMode', '?'),
        ('HasChirp', '?'),
        ('OldStartMacro', '32s', cstr),
        ('OldEndMacro', '32s', cstr),
        ('IsGapFree', '?'),
        ('HandledExternally', '?'),
        ('Filler1', '?'),
        ('Filler2', '?'),
        ('CRC', 'i'),

    ]
    size_check = 248


class ChannelPGF(TreeNode): # pfg tree second from root
    
    field_info = [
        ('Mark', 'i'),
        ('LinkedChannel', 'i'),
        ('CompressionFactor', 'i'),
        ('YUnit', '8s',cstr),
        ('AdcChannel', 'h'),
        ('AdcMode', 'c'),
        ('DoWrite', '?'),
        ('LeakStore', 'c'),
        ('AmplMode', 'c'),
        ('OwnSegTime', '?'),
        ('SetLastSeqVmemb', '?'),
        ('DacChannel', 'h'),
        ('DacMode', 'c'),
        ('HasLockInSquare', 'c'),
        ('RelevantXSegment', 'i'),
        ('RelevantYSegment', 'i'),
        ('DacUnit', '8s', cstr),
        ('Holding', 'd'),
        ('LeakHolding', 'd'),
        ('LeakSize', 'd'),
        ('LeakHoldMode', 'c'),
        ('LeakAlternate', '?'),
        ('AltLeakAveraging', '?'),
        ('LeakPulseOn', '?'),
        ('StimToDacId', 'h'),
        ('CompressionMode', 'h'),
        ('CompressionSkip', 'i'),
        ('DacBit', 'h'),
        ('HasLockInSine', '?'),
        ('BreakMode', 'c'),
        ('ZeroSeq', 'i'),
        ('StimSweep', 'i'),
        ('Sine_Cycle', 'd'),
        ('Sine_Amplitude', 'd'),
        ('LockIn_VReversal', 'd'),
        ('StartFreq', 'd'),
        ('EndFreq', 'd'),
        ('MinPoints', 'd'),
        ('NegAmpl', 'd'),
        ('Square_DurFactor', 'd'),
        ('LockIn_Skip', 'i'),
        ('Photo_MaxCycles', 'i'),
        ('Photo_SeqmentNo', 'i'),
        ('LockIn_AvgCycles', 'i'),
        ('Imaging_RoiNo', 'i'),
        ('Chirp_SKIP', 'i'),
        ('chirp_amplitude', 'd'),
        ('Photo_Adapt', 'c'),
        ('SineKind', 'c'),
        ('Chirp_PreChirp', 'c'),
        ('Sine_source', 'c'),
        ('Square_NegSource', 'c'),
        ('Square_PosSource', 'c'),
        ('Chirp_Kind', 'c'),
        ('ChirpSource', 'c'),
        ('DacOffset', 'd'),
        ('AdcOffset', 'd'),
        ('TraceMathFormat', 'c'),
        ('HasChirp', '?'),
        ('Square_kind', 'c'),
    ]
    size_check = 219
    """
    field_info = [
        ('Mark', 'i'),
        ('LinkedChannel', 'i'),
        ('CompressionFactor', 'i'),
        ('YUnit', '8s',cstr),
        ('AdcChannel', 'h'),
        ('AdcMode', 'c'),
        ('DoWrite', '?'),
        ('LeakStore', 'c'),
        ('AmplMode', 'c'),
        ('OwnSegTime', '?'),
        ('SetLastSeqVmemb', '?'),
        ('DacChannel', 'h'),
        ('DacMode', 'c'),
        ('HasLockInSquare', 'c'),
        ('RelevantXSegment', 'i'),
        ('RelevantYSegment', 'i'),
        ('DacUnit', '8s', cstr),
        ('Holding', 'd'),
        ('LeakHolding', 'd'),
        ('LeakSize', 'd'),
        ('LeakHoldMode', 'c'),
        ('LeakAlternate', '?'),
        ('AltLeakAveraging', '?'),
        ('LeakPulseOn', '?'),
        ('StimToDacId', 'h'),
        ('CompressionMode', 'h'),
        ('CompressionSkip', 'i'),
        ('DacBit', 'h'),
        ('HasLockInSine', '?'),
        ('BreakMode', 'c'),
        ('ZeroSeq', 'i'),
        ('StimSweep', 'i'),
        ('Sine_Cycle', 'd'),
        ('Sine_Amplitude', 'd'),
        ('LockIn_VReversal', 'd'),
        ('StartFreq', 'd'),
        ('EndFreq', 'd'),
        ('MinPoints', 'd'),
        ('NegAmpl', 'd'),
        ('Square_DurFactor', 'd'),
        ('LockIn_Skip', 'i'),
        ('Photo_MaxCycles', 'i'),
        ('Photo_SeqmentNo', 'i'),
        ('LockIn_AvgCycles', 'i'),
        ('Imaging_RoiNo', 'i'),
        ('Chirp_SKIP', 'i'),
        ('chirp_amplitude', 'd'),
        ('Photo_Adapt', 'c'),
        ('SineKind', 'c'),
        ('Chirp_PreChirp', 'c'),
        ('Sine_source', 'c'),
        ('Square_NegSource', 'c'),
        ('Square_PosSource', 'c'),
        ('Chirp_Kind', 'c'),
        ('ChirpSource', 'c'),
        ('DacOffset', 'd'),
        ('AdcOffset', 'd'),
        ('TraceMathFormat', 'c'),
        ('HasChirp', '?'),
        ('Square_kind', 'c'),
        ('Filler1',	'8s'), #219 -> +1
        ('Square_BaseIncr', 'd'), # + 4 /#224
        ('Square_Cycle','d'), # 232
        ('Square_PosAmpl','d'), #240
        ('CompressionOffset','i'), #248
        ('PhotoMode','i'), #252
        ('BreakLevel', 'd'), #256
        ('TraceMath', '8s'), # 264
        ('OldRC', 'i'), #268
        ('Filler2','i'), #272
        ('CRC','i') #276
    ]
    size_check = 400
    """
class StimChannelPGF(TreeNode): # pgf tree last from root
    field_info = [
        ('Mark', 'i'),
        ('Class', 'c'),
        ('Store', '?'),
        ('VoltageIncMode', 'c'),
        ('DurationIncMode', 'c'),
        ('Voltage', 'd'),
        ('VoltageSource', 'i'),
        ('DeltaVFactor', 'd'),
        ('DeltaVIncrement', 'd'),
        ('Duration', 'd'),
        ('DurationSource', 'i'),
        ('DeltaTFactor', 'd'),
        ('DeltaTIncrement', 'd'),
        ('Filler1', 'i'),
        ('CRC', 'i'),
        ('ScanRate', 'd'),

    ]
    size_check = 80
    
class Pgf(TreeNode):
    """ field info for the PGF file, manually adapted the size we maybe need to have a further look"""

    field_info = [
        ('Version', 'i'),
        ('Mark', 'i'),
        ('VersionName', '32s', cstr),
        ('MaxSample', 'i'),
        ('Filler1', 'i'),
        ('Params', 'd'),
        ('ParamsText1', '32s', cstr),
        ('ParamsText2', '32s', cstr),
        ('ParamsText3', '32s', cstr),
        ('ParamsText4', '32s', cstr),
        ('ParamsText5', '32s', cstr),
        ('ParamsText6', '32s', cstr),
        ('ParamsText7', '32s', cstr),
        ('ParamsText8', '32s', cstr),
        ('ParamsText9', '32s', cstr),
        ('ParamsText10', '32s', cstr),
        ('Reserved', 'i'),
        ('Filler2', 'i'),
        ('CRC', 'i'),
    ]
    size_check = 388

    rectypes = [
        None,
        StimulationPGF,
        ChannelPGF,
        StimChannelPGF
    ]

    def __init__(self, file_name, offset=0, size=None):
        fh = open(file_name, 'rb')
        fh.seek(offset)

        # read .pul header
        magic = fh.read(4)
        if magic == b'eerT':
            self.endian = '<'
        elif magic == b'Tree':
            self.endian = '>'
        else:
            raise RuntimeError('Bad file magic: %s' % magic)

        levels = struct.unpack(self.endian + 'i', fh.read(4))[0]

        # read size of each level (one int per level)
        self.level_sizes = []
        for i in range(levels):
            size = struct.unpack(self.endian + 'i', fh.read(4))[0]
            self.level_sizes.append(size)

        TreeNode.__init__(self, fh, self)


class Data(object):
    def __init__(self, pul, file_name, offset=0, size=None):
       
        self.offset = offset
        self.pul = pul
        self.file_name = file_name

    def __getitem__(self, *args):
        index = args[0]
        assert len(index) == 4

        trace = self.pul[index[0]][index[1]][index[2]][index[3]]

        fh = open(self.file_name, 'rb')
        fh.seek(trace.Data)

        fmt = 0#bytearray(trace.DataFormat)[0]
        dtype = [np.int16, np.int32, np.float16, np.float32][fmt]
        data = np.fromfile(fh, count=trace.DataPoints, dtype=dtype)

        #print('{:.6e}=>{:0=6.2f}e-15'.format(trace.DataScaler,trace.DataScaler/1e-15))
        roundet_scaler ='{:.6e}=>{:0=5.1f}e-15'.format(trace.DataScaler,trace.DataScaler/1e-15)
        roundet_scaler = roundet_scaler.split('=>')
        roundet_scaler = float(roundet_scaler[1])

        #print('{:.6e}=>{:0=6.2f}e-12'.format(trace.ZeroData, trace.ZeroData / 1e-12))
        roundet_zero = '{:.6e}=>{:0=6.2f}e-12'.format(trace.ZeroData, trace.ZeroData / 1e-12)
        roundet_zero = roundet_zero.split('=>')
        roundet_zero = float(roundet_zero[1])

        return_res_old = data * trace.DataScaler - trace.ZeroData
        r1 = data * trace.DataScaler + trace.ZeroData # original !!!!
        r2 = data * trace.DataScaler + trace.ZeroData/2
        r3 = data * trace.DataScaler + 2*trace.ZeroData
        r4 = data * trace.DataScaler - trace.ZeroData/2
        r5 = data * trace.DataScaler
        return_res = data* roundet_scaler + roundet_zero
        return return_res_old


def read_the_stupid_pulse():

    pathname = r"C:\Users\davee\Downloads\Test_data\Test_data\\"
    file_name = "PATCH4_2023278_07"
    suffix = ".pul"

    b = Pulsed(pathname+file_name+suffix)
    return b

def read_the_stupid_pgf():
    pathname = r"C:\Users\davee\Downloads\Test_data\Test_data\\"
    file_name = "PATCH4_2023278_07"
    suffix = ".pul"

    b = Pgf(pathname+file_name+suffix)
    return b

def read_the_stupid_data(pul:Pulsed):
    pathname = r"C:\Users\davee\Downloads\Test_data\Test_data\\"
    file_name = "PATCH4_2023278_07"
    suffix = ".dat"

    b = Data(pul, pathname+file_name+suffix)
    return b